{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final_v2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1MqGRLavWhD93eztIxjicE-UYIqdwfADr","authorship_tag":"ABX9TyOeUkB496BoukPCKI0eKaV0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WropP8FqCeDj","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","import numpy as np\n","import pandas as pd\n","import os\n","import time\n","\n","import datetime\n","import math\n","import scipy\n","from scipy.sparse import hstack\n","from sklearn.preprocessing import StandardScaler\n","from nltk.corpus import stopwords\n","from tqdm import tqdm\n","import re\n","import gc\n","import pickle\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Loading Tensorflow libraries\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense,Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.models import load_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yrQbOTA9ed92","colab_type":"code","colab":{}},"source":["os.chdir(\"/content/drive/My Drive\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"83Jst6QlC_DU","colab_type":"code","colab":{}},"source":["def preprocess(df):\n","  df['name'] = df['name'].fillna('') + ' ' + df['brand_name'].fillna('')\n","  df['text'] = (df['item_description'].fillna('') + ' ' + df['name'] + ' ' +df['category_name'].fillna(''))\n","  return df[['name', 'text', 'shipping', 'item_condition_id']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6zG9S-hTDc0j","colab_type":"code","colab":{}},"source":["def clean_data(train_data):\n","  # Since Mercari App doesn't allow price to be less than 3 or grater than\n","  # 2000, we need to remove those kind of data from training data\n","\n","  train_data = train_data[(train_data.price >= 3) & (train_data.price <=2000)].reset_index(drop=True)\n","\n","  return train_data\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t323TckuD3gk","colab_type":"code","colab":{}},"source":["# Defining RMSLE Score\n","\n","def rmsle_score(y, y_pred):\n","  assert len(y) == len(y_pred)\n","  to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n","  return (sum(to_sum) * (1.0/len(y))) ** 0.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n5GbICEsFhWn","colab_type":"code","colab":{}},"source":["# Building the MLP Model\n","\n","def build_model(train_shape):\n","  input_layer = Input(shape=(train_shape,), dtype = 'float32',sparse = True)\n","\n","  layer1 = Dense(256,activation = \"relu\",\n","                 kernel_initializer=tf.keras.initializers.he_uniform(seed = 42))(input_layer)\n","\n","  layer2 = Dense(64,activation = \"relu\",\n","                 kernel_initializer=tf.keras.initializers.he_uniform(seed = 42))(layer1)\n","\n","  layer3 = Dense(64,activation = \"relu\",\n","                 kernel_initializer=tf.keras.initializers.he_uniform(seed = 42))(layer2)\n","\n","  layer4 = Dense(32,activation = \"relu\",\n","                 kernel_initializer=tf.keras.initializers.he_uniform(seed = 42))(layer3)\n","\n","  output_layer = Dense(1,kernel_initializer=tf.keras.initializers.he_uniform(seed = 42))(layer4)\n","\n","  model = Model(inputs = input_layer, outputs = output_layer)\n","\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWGqPbmPL389","colab_type":"code","colab":{}},"source":["def Vectorize_train_data(train_data):\n","\n","  # Vectorizing the Name Column and Dumping the Object\n","  Vectorizer = TfidfVectorizer(max_features=100000,\n","                               token_pattern='\\w+',dtype=np.float32)\n","  Vectorizer.fit(train_data['name'].values)\n","  X_train_name = Vectorizer.transform(train_data['name'].values)\n","\n","  f = open(\"Name_Vectorizer\",\"wb\")\n","  pickle.dump(Vectorizer,f)\n","  f.close()\n","\n","  # Vectorizing the Text Column and Dumping the Object\n","  Vectorizer = TfidfVectorizer(max_features=100000,ngram_range =(1,2),\n","                               token_pattern='\\w+',dtype=np.float32)\n","  Vectorizer.fit(train_data['text'].values)\n","  X_train_text = Vectorizer.transform(train_data['text'].values)\n","\n","  f = open(\"Text_Vectorizer\",\"wb\")\n","  pickle.dump(Vectorizer,f)\n","  f.close()\n","\n","\n","  # OneHotEncoding the Shipping Column and Dumping the Object\n","  Vectorizer = OneHotEncoder(dtype=np.float32)\n","  X_train_ship = Vectorizer.fit_transform(train_data['shipping'].values.reshape(-1,1))\n","  \n","  f = open(\"Ship_Vectorizer\",\"wb\")\n","  pickle.dump(Vectorizer,f)\n","  f.close()\n","\n","  # OneHotEncoding the Item Condition Id and Dumping the Object\n","  Vectorizer = OneHotEncoder(dtype=np.float32)\n","  X_train_item = Vectorizer.fit_transform(train_data['item_condition_id'].values.reshape(-1,1))\n","  \n","  f = open(\"Item_Vectorizer\",\"wb\")\n","  pickle.dump(Vectorizer,f)\n","  f.close()\n","\n","\n","  # Stacking up all the Features\n","  X_train_tfidf = hstack((X_train_name,X_train_text,\n","                         X_train_ship,X_train_item)).tocsr()\n","  \n","\n","  # Binarizing the Features\n","\n","  # X_train_binary = [x.astype(np.bool).astype(np.float32) for x in [X_train_tfidf]]\n","  X_train_binary = X_train_tfidf.astype(np.bool).astype(np.float32)\n","\n","  \n","  print(\"X_train TFIDF Shape : \",X_train_tfidf.shape)\n","  print(\"X_train Binarized Shape : \",X_train_binary.shape)\n","\n","  return X_train_tfidf,X_train_binary"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0RdS8XM9H_tx","colab_type":"text"},"source":["The Training Function trains the Ensemble Model on the Train Data and saves the Model and object using a pickle file."]},{"cell_type":"code","metadata":{"id":"OSKjb8GFJww1","colab_type":"code","colab":{}},"source":["def training():\n","\n","  # Reading the Input Training Data\n","  train_data = pd.read_csv('train/train.tsv',sep = '\\t')\n","\n","  # Selecting every row except the last five rows\n","  train_data.drop(train_data.tail(5).index,inplace=True)\n","\n","  train_data = clean_data(train_data)\n","\n","\n","  # Log Transformation of the Price Column and Dumping the Object\n","  scaler = StandardScaler()\n","  y_train = scaler.fit_transform(np.log1p(train_data['price'].values.reshape(-1, 1)))\n","\n","  f = open(\"Standard_Scaler\",\"wb\")\n","  pickle.dump(scaler,f)\n","  f.close()\n","\n","  # Pre-processing the Train Data\n","  train_data = preprocess(train_data)\n","\n","  X_train_tfidf,X_train_binary = Vectorize_train_data(train_data)\n","  \n","  del train_data\n","  gc.collect()\n","\n","  # MLP1\n","\n","  mlp1 = build_model(X_train_tfidf.shape[1])\n","  mlp1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.003),\n","               loss= \"mean_squared_error\")\n","  \n","  for i in range(2):\n","    mlp1.fit(X_train_tfidf,y_train, batch_size= 2**(9 + i),\n","             epochs = 1,verbose= 1)\n","  \n","  # Saving the MLP1 Model\n","  mlp1.save(\"mlp1.h5\")\n","\n","  print(\"Saved Model 1\")\n","\n","  # MLP2\n","\n","  mlp2 = build_model(X_train_binary.shape[1])\n","  mlp2.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.003),\n","               loss= \"mean_squared_error\")\n","  \n","  for i in range(2):\n","    mlp2.fit(X_train_binary,y_train, batch_size= 2**(9 + i), \n","             epochs = 1,verbose= 1)\n","\n","\n","  # Saving the MLP2 Model\n","  mlp1.save(\"mlp2.h5\")\n","\n","  print(\"Saved Model 2\")\n","\n","  print(\"Training Done.\")\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gLvqXYqBfpDi","colab_type":"code","colab":{}},"source":["def function1(test_data):\n","\n","  print(\"Testing on the Test Data..\")\n","\n","  # Pre-processing the Test Data\n","  test_data = preprocess(test_data)\n","\n","  # Vectorizing the Name Column in Test Data\n","  f = open(\"Name_Vectorizer\",\"rb\")\n","  Vectorizer = pickle.load(f)\n","  f.close()\n","\n","  X_test_name = Vectorizer.transform(test_data['name'].values)\n","\n","  # Vectorizing the Text Column in Test Data   \n","  f = open(\"Text_Vectorizer\",\"rb\")\n","  Vectorizer = pickle.load(f)\n","  f.close()\n","\n","  X_test_text = Vectorizer.transform(test_data['text'].values)\n","\n","  # OneHotEncoding the Shipping Column in Test Data\n","  f = open(\"Ship_Vectorizer\",\"rb\")\n","  Vectorizer = pickle.load(f)\n","  f.close()\n","\n","  X_test_ship = Vectorizer.transform(test_data['shipping'].values.reshape(-1,1))\n","\n","  # OneHotEncoding the Item Condition Column in Test Data\n","  f = open(\"Item_Vectorizer\",\"rb\")\n","  Vectorizer = pickle.load(f)\n","  f.close()\n","\n","  X_test_item = Vectorizer.transform(test_data['item_condition_id'].values.reshape(-1,1))\n","\n","  # Stacking up all the Features\n","  X_test_tfidf = hstack((X_test_name,X_test_text,\n","                         X_test_ship,X_test_item)).tocsr()\n","  \n","\n","  # Binarizing the Features\n","  X_test_binary = X_test_tfidf.astype(np.bool).astype(np.float32) \n","\n","\n","  print(\"X_test TFIDF Shape : \",X_test_tfidf.shape)\n","  print(\"X_test Binarized Shape : \",X_test_binary.shape)\n","\n","  # Loading the MLP1 and MLP2 \n","  mlp1 = load_model(\"mlp1.h5\")\n","\n","  mlp2 = load_model(\"mlp2.h5\")\n","\n","  # Predicting the Value based on the Model Trained\n","\n","  y_pred1 = mlp1.predict(X_test_tfidf)[:,0]\n","\n","  f = open(\"Standard_Scaler\",\"rb\")\n","  scaler = pickle.load(f)\n","  f.close()\n","\n","  y_pred1 = np.expm1(scaler.inverse_transform(y_pred1.reshape(-1, 1))[:, 0])\n","\n","  y_pred2 = mlp2.predict(X_test_binary)[:,0]\n","\n","  y_pred2 = np.expm1(scaler.inverse_transform(y_pred2.reshape(-1, 1))[:, 0])\n","\n","  # Generating Emsemble of the above two MLP's\n","\n","  y_prediction = 0.55 * y_pred1 + 0.45 * y_pred2\n","\n","  print(\"Testing Done...\")\n","\n","  return y_prediction\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0oY2EmO2OJ3s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"51053cc4-c2b5-4b03-b35a-64aa53ee1b9c","executionInfo":{"status":"ok","timestamp":1591641860643,"user_tz":-330,"elapsed":338424,"user":{"displayName":"Rajat Yadav","photoUrl":"","userId":"04685338058680220660"}}},"source":["training()   # Training the Model and Saving Model and Objects accordingly"],"execution_count":10,"outputs":[{"output_type":"stream","text":["X_train TFIDF Shape :  (1481653, 200007)\n","X_train Binarized Shape :  (1481653, 200007)\n","2894/2894 [==============================] - 22s 8ms/step - loss: 0.3414\n","1447/1447 [==============================] - 15s 10ms/step - loss: 0.2025\n","Saved Model 1\n","2894/2894 [==============================] - 24s 8ms/step - loss: 0.3496\n","1447/1447 [==============================] - 15s 10ms/step - loss: 0.2097\n","Saved Model 2\n","Training Done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LCZnik_o5QA5","colab_type":"text"},"source":["# Function 1\n","In Function1 we need to predict the Y(Price) value hence we will be training on the Entire train data except the last 5 rows and will compare the Actual Y(Price) value and the Predicted Y(Price) value."]},{"cell_type":"code","metadata":{"id":"vpgw7UYyecSz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1a949673-b00c-437e-e7b7-5405eaca2e1c","executionInfo":{"status":"ok","timestamp":1591641873223,"user_tz":-330,"elapsed":350967,"user":{"displayName":"Rajat Yadav","photoUrl":"","userId":"04685338058680220660"}}},"source":["df_test = pd.read_csv('train/train.tsv',sep = '\\t')\n","test_data = df_test.tail(5)  # Keeping the last 5 records as test \n","\n","y_pred = function1(test_data)\n","\n","i = 0\n","for index,row in test_data.iterrows():\n","  print(\"Input Data : \")\n","  print(row[['name','item_description','category_name',\n","                             'brand_name','shipping','item_condition_id']])\n","  print(\"Actual Price : \",row['price'])\n","  print(\"Predicted Price : \",y_pred[i])\n","  i = i + 1\n","  print(\"*\"*80)\n","  "],"execution_count":11,"outputs":[{"output_type":"stream","text":["Testing on the Test Data..\n","X_test TFIDF Shape :  (5, 200007)\n","X_test Binarized Shape :  (5, 200007)\n","Testing Done...\n","Input Data : \n","name                            Free People Inspired Dress Free People\n","item_description     Lace, says size small but fits medium perfectl...\n","category_name                                   Women/Dresses/Mid-Calf\n","brand_name                                                 Free People\n","shipping                                                             1\n","item_condition_id                                                    2\n","Name: 1482530, dtype: object\n","Actual Price :  20.0\n","Predicted Price :  14.395757\n","********************************************************************************\n","Input Data : \n","name                             Little mermaid handmade dress Disney\n","item_description     Little mermaid handmade dress never worn size 2t\n","category_name                                Kids/Girls 2T-5T/Dresses\n","brand_name                                                     Disney\n","shipping                                                            0\n","item_condition_id                                                   2\n","Name: 1482531, dtype: object\n","Actual Price :  14.0\n","Predicted Price :  8.884997\n","********************************************************************************\n","Input Data : \n","name                         21 day fix containers and eating plan \n","item_description          Used once or twice, still in great shape.\n","category_name        Sports & Outdoors/Exercise/Fitness accessories\n","brand_name                                                      NaN\n","shipping                                                          0\n","item_condition_id                                                 2\n","Name: 1482532, dtype: object\n","Actual Price :  12.0\n","Predicted Price :  33.529602\n","********************************************************************************\n","Input Data : \n","name                                           World markets lanterns \n","item_description     There is 2 of each one that you see! So 2 red ...\n","category_name                       Home/Home Décor/Home Décor Accents\n","brand_name                                                         NaN\n","shipping                                                             1\n","item_condition_id                                                    3\n","Name: 1482533, dtype: object\n","Actual Price :  45.0\n","Predicted Price :  16.089226\n","********************************************************************************\n","Input Data : \n","name                                    Brand new lux de ville wallet \n","item_description     New with tag, red with sparkle. Firm price, no...\n","category_name                        Women/Women's Accessories/Wallets\n","brand_name                                                         NaN\n","shipping                                                             0\n","item_condition_id                                                    1\n","Name: 1482534, dtype: object\n","Actual Price :  22.0\n","Predicted Price :  33.35273\n","********************************************************************************\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0fSQSXLIecAO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ffwdqd39eb9N","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CEgqqd-T5lIl","colab_type":"text"},"source":["# Function 2\n","In Function 2 we need to check the metric(RMSLE) value where we will train the model using the Entire except the last 5 rows of training data and will pass the actual Price value and predicted Price value to check the RMSLE value."]},{"cell_type":"code","metadata":{"id":"47N95VsT4-nx","colab_type":"code","colab":{}},"source":["def function2(X_input,y_value):\n","  y_pred = function1(X_input)\n","  y_pred = np.asarray(y_pred)\n","  rmsle_value = rmsle_score(y_value,y_pred)\n","  return rmsle_value"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KuAbmuSn6clZ","colab_type":"code","outputId":"8bdc0d43-30d4-4091-df88-231aca886406","executionInfo":{"status":"ok","timestamp":1591641885309,"user_tz":-330,"elapsed":362871,"user":{"displayName":"Rajat Yadav","photoUrl":"","userId":"04685338058680220660"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["df_test = pd.read_csv('train/train.tsv',sep = '\\t')\n","\n","# Reading the only 5 rows of training data\n","df_input = df_test.tail(5)\n","actual_price = np.asarray(df_input['price'].values)\n","\n","rmsle = function2(df_input,actual_price)\n","print(\"RMSLE Value : \",rmsle)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Testing on the Test Data..\n","X_test TFIDF Shape :  (5, 200007)\n","X_test Binarized Shape :  (5, 200007)\n","Testing Done...\n","RMSLE Value :  0.6878934461452819\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dIBHeLzL-mbA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}