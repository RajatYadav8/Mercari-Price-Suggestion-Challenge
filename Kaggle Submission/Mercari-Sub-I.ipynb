{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"Mercari-Sub-I.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"trusted":true,"id":"2NbPTUJjYzU5","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","import numpy as np\n","import pandas as pd\n","import os\n","import time\n","from py7zr import unpack_7zarchive\n","# from pyunpack import Archive\n","import shutil\n","import datetime\n","import math\n","from contextlib import contextmanager\n","import scipy\n","from scipy.sparse import hstack\n","from sklearn.preprocessing import StandardScaler\n","from nltk.corpus import stopwords\n","from tqdm import tqdm\n","import re\n","import gc\n","import pickle\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import KFold\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense,Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import EarlyStopping"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U5QxLnD-aRNY","colab_type":"code","colab":{}},"source":["os.chdir(\"/content/drive/My Drive/Kaggle Case Study I\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"vRqMd2h_YzU_","colab_type":"code","colab":{}},"source":["def extract_zip(input_path,output_path):\n","    if not os.path.exists(output_path):\n","        os.makedirs(output_path)\n","    try:\n","        shutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)\n","        shutil.unpack_archive(input_path, output_path)\n","    except Exception as e:\n","        shutil.unpack_archive(input_path, output_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"Rsb0Da2gYzVD","colab_type":"code","colab":{}},"source":["def load_data():\n","    train_data = pd.read_csv('train/train.tsv',sep = '\\t')\n","    test_data = pd.read_csv('test_stg2/test_stg2.tsv',sep = '\\t')\n","    return train_data,test_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"HmXUmTJUYzVI","colab_type":"code","colab":{}},"source":["def preprocess(df):\n","    df['name'] = df['name'].fillna('') + ' ' + df['brand_name'].fillna('')\n","    df['text'] = (df['item_description'].fillna('') + ' ' + df['name'] + ' ' + df['category_name'].fillna(''))\n","    return df[['name', 'text', 'shipping', 'item_condition_id']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"1bj7KdSlYzVR","colab_type":"code","colab":{}},"source":["def main():\n","    \n","    start = time.time()\n","    \n","    # Reading the Input Data\n","    # extract_zip(\"train.tsv.7z\",\"train/\")\n","    # extract_zip(\"test.tsv.7z\",\"test/\")\n","    \n","    train_data,test_data = load_data()\n","    \n","    train_data = train_data[(train_data.price >= 3) & (train_data.price <= 2000)].reset_index(drop=True)\n","    print(\"(1) done\")\n","    #####################################################################################################\n","    \n","    # Vectorizing the Data\n","    scaler = StandardScaler()\n","    y_train = scaler.fit_transform(np.log1p(train_data['price'].values.reshape(-1, 1)))\n","    \n","    train_data = preprocess(train_data)\n","    test_data = preprocess(test_data)\n","    \n","    Vectorizer = TfidfVectorizer(max_features=100000,token_pattern='\\w+', dtype=np.float32)\n","    Vectorizer.fit(train_data['name'].values)\n","    \n","    X_train_name = Vectorizer.transform(train_data['name'].values)\n","    X_test_name = Vectorizer.transform(test_data['name'].values)\n","    \n","    Vectorizer = TfidfVectorizer(max_features=100000,ngram_range = (1,2),token_pattern='\\w+', dtype=np.float32)\n","    Vectorizer.fit(train_data['text'].values)\n","    \n","    X_train_text = Vectorizer.transform(train_data['text'].values)\n","    X_test_text = Vectorizer.transform(test_data['text'].values)\n","    \n","    Vectorizer = OneHotEncoder(dtype=np.float32)\n","    X_train_ship = Vectorizer.fit_transform(train_data['shipping'].values.reshape(-1,1))\n","    X_test_ship = Vectorizer.transform(test_data['shipping'].values.reshape(-1,1))\n","    \n","    Vectorizer = OneHotEncoder(dtype=np.float32)\n","    X_train_item = Vectorizer.fit_transform(train_data['item_condition_id'].values.reshape(-1,1))\n","    X_test_item = Vectorizer.transform(test_data['item_condition_id'].values.reshape(-1,1))\n","    \n","    X_train_tfidf = hstack((X_train_name,X_train_text,X_train_ship,X_train_item)).tocsr()\n","    X_test_tfidf = hstack((X_test_name,X_test_text,X_test_ship,X_test_item)).tocsr()\n","    \n","    del X_train_name,X_test_name,X_train_text,X_test_text,X_train_ship,X_test_ship,X_train_item,X_test_item\n","    del train_data\n","    gc.collect()\n","    \n","    X_train_binary, X_test_binary = [x.astype(np.bool).astype(np.float32) for x in [X_train_tfidf, X_test_tfidf]]\n","    \n","    print(\"X_train TFIDF Shape : \",X_train_tfidf.shape)\n","    print(\"X_train Binarized Shape : \",X_train_binary.shape)\n","    print(\"X_test TFIDF Shape : \",X_test_tfidf.shape)\n","    print(\"X_test Binarized Shape : \",X_test_binary.shape)\n","    \n","    print(\"(2) done\")\n","    #####################################################################################################\n","    \n","    # Saving the Pre-processed file into a pickle file along with the test id's\n","\n","    file = open(\"X_train_tfidf\",\"wb\")\n","    pickle.dump(X_train_tfidf,file)\n","    file.close()\n","\n","    file = open(\"X_test_tfidf\",\"wb\")\n","    pickle.dump(X_test_tfidf,file)\n","    file.close()\n","\n","    file = open(\"X_train_binary\",\"wb\")\n","    pickle.dump(X_train_binary,file)\n","    file.close()\n","\n","    file = open(\"X_test_binary\",\"wb\")\n","    pickle.dump(X_test_binary,file)\n","    file.close()\n","    \n","    #####################################################################################################\n","    end = time.time()\n","    print(\"Time Taken in Seconds : \", end - start)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"b7tsia7TYzVV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"7a379016-e0e0-4ecd-8294-7f14cb6cffac","executionInfo":{"status":"ok","timestamp":1590580061564,"user_tz":-330,"elapsed":485458,"user":{"displayName":"Rajat Yadav","photoUrl":"","userId":"12954724038430005995"}}},"source":["if __name__ == \"__main__\":\n","    main()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(1) done\n","X_train TFIDF Shape :  (1481658, 200007)\n","X_train Binarized Shape :  (1481658, 200007)\n","X_test TFIDF Shape :  (3460725, 200007)\n","X_test Binarized Shape :  (3460725, 200007)\n","(2) done\n","Time Taken in Seconds :  576.8102276325226\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"muo5x3TnucwI","colab_type":"code","colab":{}},"source":["train_data,test_data = load_data()\n","test_data.test_id.to_csv(\"test_id.csv\",index=False)"],"execution_count":0,"outputs":[]}]}